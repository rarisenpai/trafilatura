
Filed under:



Apple




Tech




iOS



iOS 13 will fix the FaceTime eye contact problem


    New,
  


      74
    
comments

Fake eye contact for improved intimacy

  
    By
    
Jon Porter@JonPorty



        Jul  3, 2019,  4:22am EDT
      
Share this story



Share this on Facebook




Share this on Twitter




Share
All sharing options




Share
All sharing options for:
iOS 13 will fix the FaceTime eye contact problem




Facebook




Twitter




Linkedin




Reddit




Pocket




Flipboard




Email





Photo by Dan Seifert / The Verge


iOS 13’s third developer beta includes a new feature that makes it look like you’re staring directly at your front-facing camera during FaceTime calls, even when looking away at the person on your screen. The feature, which was spotted by Mike Rundle on Twitter, only appears to be working on the iPhone XS and XS Max with this version of the beta, and can be toggled on and off from within FaceTime’s settings.
Normally, video calls tend to make it look like both participants are peering off to one side or the other, since they’re looking at the person on their display, rather than directly into the front-facing camera.  However, the new “FaceTime Attention Correction” feature appears to use some kind of image manipulation to correct this, and results in realistic-looking fake eye contact between the FaceTime users. Coincidentally, Rundle himself theorized back in 2017 that Apple would one day do this, although not so soon. 


Normally if you look at a portrait phone screen, you appear to be looking below the front-facing camera.
Image: WSig




With the new feature, you appear to be looking at the camera, even when you’re looking at the screen.
Image: WSig


On Twitter, Dave Schukin explains that the effect is being achieved using ARKit, which is used to map a user’s face and adjust the positioning of their eyes accordingly. Using the arm from a pair of glasses, Schukin shows how the software is warping the eye area slightly to achieve the effect. The same effect also appears to be present when wearing sunglasses. 

How iOS 13 FaceTime Attention Correction works: it simply uses ARKit to grab a depth map/position of your face, and adjusts the eyes accordingly.Notice the warping of the line across both the eyes and nose. pic.twitter.com/U7PMa4oNGN— Dave Schukin   (@schukin) July 3, 2019

It’s not clear which devices the feature will eventually work with, or whether it will support group calls. We’re also curious to know whether it works when there are multiple people in the frame, for those times when you group your entire family round a device to FaceTime a distant relative. The feature should arrive in the public-facing beta next week.
Update July 3rd, 8:05AM ET: Added ARKit explanation and tweet.

    Next Up In
    
        Tech



Verge3.0_Logomark_Color_1




        Sign up for the
        
          newsletter
        
      
      Command Line
    
Command Line delivers daily updates from the near-future.




  This Article has a component height of 20. The sidebar size is long.







Loading comments...
