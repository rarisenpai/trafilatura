Will Knight Business01.21.2020 07:00 AMAI Can Do Great Things‚Äîif It Doesn't Burn the PlanetThe computing power required for AI landmarks, such as recognizing images and defeating humans at Go, increased 300,000-fold from 2012 to 2018. FacebookTwitterEmailOne algorithm that lets a robot manipulate a Rubik's Cube used as much energy as 3 nuclear plants produce in an hour.Photograph: Getty ImagesLast month, researchers at OpenAI in San Francisco revealed an algorithm capable of learning, through trial and error, how to manipulate the pieces of a Rubik's Cube using a robotic hand. It was a remarkable research feat, but it required more than 1,000 desktop computers plus a dozen machines running specialized graphics chips crunching intensive calculations for several months.The effort may have consumed about 2.8 gigawatt-hours of electricity, estimates Evan Sparks, CEO of Determined AI, a startup that provides software to help companies manage AI projects. That‚Äôs roughly equal to the output of three nuclear power plants for an hour. A spokesperson for OpenAI questioned the calculation, noting that it makes several assumptions. But OpenAI declined to disclose further details of the project or offer an estimate of the electricity it consumed.Artificial intelligence routinely produces startling achievements, as computers learn to recognize images, converse, beat humans at sophisticated games, and drive vehicles. But all those advances require staggering amounts of computing power‚Äîand electricity‚Äîto devise and train algorithms. And as the damage caused by climate change becomes more apparent, AI experts are increasingly troubled by those energy demands.‚ÄúThe concern is that machine-learning algorithms in general are consuming more and more energy, using more data, training for longer and longer,‚Äù says Sasha Luccioni, a postdoctoral researcher at Mila, an AI research institute in Canada.It‚Äôs not just a worry for academics. As more companies across more industries begin to use AI, there‚Äôs growing fear that the technology will only deepen the climate crisis. Sparks says that Determined.ai is working with a pharmaceutical firm that‚Äôs already using huge AI models. ‚ÄúAs an industry, it‚Äôs worth thinking about how we want to combat this,‚Äù he adds.Some AI researchers are thinking about it. They‚Äôre using tools to track the energy demands of their algorithms, or taking steps to offset their emissions. A growing number are touting the energy efficiency of their algorithms in research papers and at conferences. As the costs of AI rise, the AI industry is developing a new appetite for algorithms that burn fewer kilowatts.Luccioni recently helped launch a website that lets AI researchers roughly calculate the carbon footprint of their algorithms. She is also testing a more sophisticated approach‚Äîcode that can be added to an AI program to track the energy use of individual computer chips. Luccioni and others are also trying to persuade companies that offer tools for tracking the performance of code to include some measure of energy or carbon footprint. ‚ÄúHopefully this will go toward full transparency,‚Äù she says. ‚ÄúSo that people will include in the footnotes ‚Äòwe emitted X tons of carbon, which we offset.‚Äô‚ÄùThe energy required to power cutting-edge AI has been on a steep upward curve for some time. Data published by OpenAI shows that the computing power required for key AI landmarks over the past few years, such as DeepMind‚Äôs Go-playing program AlphaZero, has doubled roughly every 3.4 months‚Äîincreasing 300,000 times between 2012 and 2018. That‚Äôs faster than the rate at which computing power historically increased, the phenomenon known as Moore‚Äôs Law (named after Gordon Moore, cofounder of Intel.)Recent advances in natural language processing‚Äîan AI technique that helps machines parse, interpret, and generate text‚Äîhave proven especially power-hungry. A research paper from a team at UMass Amherst found that training a single large NLP model may consume as much energy as a car over its entire lifetime‚Äîincluding the energy needed to build it.Training a powerful machine-learning algorithm often means running huge banks of computers for days, if not weeks. The fine-tuning required to perfect an algorithm, by for example searching through different neural network architectures to find the best one, can be especially computationally intensive. For all the hand-wringing, though, it remains difficult to measure how much energy AI actually consumes, and even harder to predict how much of a problem it could become.AdvertisementThe Department of Energy estimates that data centers account for about 2 percent of total US electricity usage. Worldwide, data centers consume about 200 terawatt hours of power per year‚Äîmore than some countries. And the forecast is for significant growth over the next decade, with some predicting that by 2030, computing and communications technology will consume between 8 percent and 20 percent of the world‚Äôs electricity, with data centers accounting for a third of that.In recent years, companies offering cloud computing services have sought to address spiraling power consumption and offset carbon emissions with varying measures of success. Google, for example, claims ‚Äúzero net carbon emissions‚Äù for its data centers, thanks to extensive renewable energy purchases. Microsoft last week announced a plan to become ‚Äúcarbon negative‚Äù by 2030, meaning it would offset all of the carbon produced by the company over its history. OpenAI signed a deal to use Microsoft's cloud last July.It isn‚Äôt clear how the AI boom will fit with the bigger picture of data center energy use, or how it might alter it. Cloud providers do not disclose the overall energy demands of machine-learning systems. Microsoft, Amazon, and Google all declined to comment.Keep ReadingThe latest on artificial intelligence, from machine learning to computer vision and moreJonathan Koomey, a researcher and consultant who tracks data center energy use, cautions against drawing too many conclusions from cutting-edge AI demos. He notes that AI algorithms often run on specialized chips that are more efficient, so new chip architectures may offset some of the projected demand for compute power. He also says that the IT industry has in the past offset rising energy demands in one domain by lowering energy use in others. ‚ÄúPeople are likely to take isolated anecdotes and extrapolate to get eye popping numbers, and these numbers are almost always too high,‚Äù Koomey says.Still, as companies and other organizations increasingly use artificial intelligence, experts say it will become important to understand the technology‚Äôs energy footprint, both in data centers and in other devices and gadgets. ‚ÄúI would agree that the analysis community needs to get a handle on it,‚Äù says Eric Masanet, a professor at Northwestern University who leads its Energy and Resource Systems Analysis Laboratory.Some AI researchers aren‚Äôt waiting for the industry to wake up. Luccioni of Mila helped organize a workshop on climate change last month at an important AI conference, NeurIPS, and she was pleased to find that the event was standing room only. ‚ÄúThere‚Äôs a lot of interest in this,‚Äù she says.The Allen Institute for AI, a research institute founded by the late Microsoft cofounder Paul Allen, has also called for greater awareness of AI‚Äôs environmental impact. The institute‚Äôs CEO, Oren Etzioni, says he is encouraged by the efforts of researchers, as many papers now include some account of the computational intensity of a particular algorithm or experiment.Etzioni adds that the industry as a whole is gradually waking up to energy efficiency. Even if this is largely because of the cost involved with training large AI models, it could help prevent AI from contributing to a looming climate catastrophe. ‚ÄúAI is clearly moving toward lighter models and greener AI,‚Äù he says.More Great WIRED StoriesChris Evans goes to WashingtonWhat Atlanta can teach tech about cultivating black talentThe display of the future might be in your contact lensHere's what the world will look like in 2030 ... right?The war vet, the dating site, and the phone call from hellüëÅ The case for a light hand with AI. Plus, the latest news on artificial intelligenceüèÉüèΩ‚Äç‚ôÄÔ∏è Want the best tools to get healthy? Check out our Gear team‚Äôs picks for the best fitness trackers, running gear (including shoes and socks), and best headphones