iOS 13’s third developer beta includes a new feature that makes it look like you’re staring directly at your front-facing camera during FaceTime calls, even when looking away at the person on your screen. The feature, which was spotted by Mike Rundle on Twitter, only appears to be working on the iPhone XS and XS Max with this version of the beta, and can be toggled on and off from within FaceTime’s settings.
Normally, video calls tend to make it look like both participants are peering off to one side or the other, since they’re looking at the person on their display, rather than directly into the front-facing camera. However, the new “FaceTime Attention Correction” feature appears to use some kind of image manipulation to correct this, and results in realistic-looking fake eye contact between the FaceTime users. Coincidentally, Rundle himself theorized back in 2017 that Apple would one day do this, although not so soon.
On Twitter, Dave Schukin explains that the effect is being achieved using ARKit, which is used to map a user’s face and adjust the positioning of their eyes accordingly. Using the arm from a pair of glasses, Schukin shows how the software is warping the eye area slightly to achieve the effect. The same effect also appears to be present when wearing sunglasses.
How iOS 13 FaceTime Attention Correction works: it simply uses ARKit to grab a depth map/position of your face, and adjusts the eyes accordingly.— Dave Schukin (@schukin) July 3, 2019
Notice the warping of the line across both the eyes and nose. pic.twitter.com/U7PMa4oNGN
It’s not clear which devices the feature will eventually work with, or whether it will support group calls. We’re also curious to know whether it works when there are multiple people in the frame, for those times when you group your entire family round a device to FaceTime a distant relative. The feature should arrive in the public-facing beta next week.
Update July 3rd, 8:05AM ET: Added ARKit explanation and tweet.